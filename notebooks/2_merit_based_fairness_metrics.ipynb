{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merit-Based Fairness Metrics\n",
    "\n",
    "**Category Focus:** *\"Protecting qualified individuals\"*\n",
    "\n",
    "This notebook explores Merit-Based Fairness Metrics that ensure qualified people get fair opportunities and innocent people aren't wrongly penalized. These metrics focus on **fair outcomes** based on actual merit, making them essential for high-stakes decisions like hiring, admissions, and promotions.\n",
    "\n",
    "## Metrics in This Category\n",
    "\n",
    "1. **Equal Opportunity** - Qualified candidates get equal chances\n",
    "2. **Average Odds** - Metric summarizing TPR/FPR differences across groups (used to assess how close you are to Equalized Odds)\n",
    "3. **Predictive Equality** - Ensures that innocent individuals have equal protection from false approvals across all demographic groups\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Descriptive Analysis\n",
    "\n",
    "### Equal Opportunity\n",
    "**Definition:** Ensures that individuals who deserve a positive outcome have an equal chance of receiving it across demographic groups.\n",
    "\n",
    "**Formula:** TPR (True Positive Rate) should be equal across groups\n",
    "- TPR_group1 â‰ˆ TPR_group2\n",
    "- Where TPR = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "**Business Meaning:** \n",
    "- Qualified candidates from all demographic groups have equal chances of being selected\n",
    "- Prevents systematic exclusion of qualified talent from underrepresented groups\n",
    "- Critical for merit-based hiring and promotion decisions\n",
    "\n",
    "**When to Use:**\n",
    "- Hiring processes where missing qualified candidates is costly\n",
    "- College admissions to ensure qualified students aren't overlooked\n",
    "- Promotion decisions to maintain talent pipeline equity\n",
    "\n",
    "---\n",
    "\n",
    "### Average Odds\n",
    "**Definition:** A metric that measures how far a model is from satisfying Equalized Odds by calculating the average difference in TPR and FPR across demographic groups.\n",
    "\n",
    "**Formula:** Average of TPR and FPR differences across groups\n",
    "- Average Odds = (|TPR_group1 - TPR_group2| + |FPR_group1 - FPR_group2|) / 2\n",
    "- Where TPR = True Positive Rate and FPR = False Positive Rate\n",
    "\n",
    "**Relationship to Equalized Odds:**\n",
    "- **Average Odds** is a *metric* that quantifies unfairness\n",
    "- **Equalized Odds** is a *fairness constraint* (the goal: TPR and FPR equal across groups)\n",
    "- Lower Average Odds scores indicate closer proximity to achieving Equalized Odds\n",
    "\n",
    "**Business Meaning:**\n",
    "- Measures comprehensive fairness for both qualified candidates and those who don't meet criteria\n",
    "- Assesses whether the model treats both groups equally in terms of true positives (qualified) and false positives (unqualified)\n",
    "- Provides a single score to track progress toward the Equalized Odds fairness goal\n",
    "\n",
    "**When to Use:**\n",
    "- High-stakes decisions with dual concerns (hiring + avoiding poor hires)\n",
    "- Credit lending (protect good borrowers + avoid bad loans)\n",
    "- Medical diagnosis (catch diseases + avoid false alarms)\n",
    "\n",
    "---\n",
    "\n",
    "### Predictive Equality\n",
    "**Definition:** Ensures that individuals who don't deserve a positive outcome have equal protection from false approvals across demographic groups.\n",
    "\n",
    "**Formula:** FPR (False Positive Rate) should be equal across groups\n",
    "- FPR_group1 â‰ˆ FPR_group2\n",
    "- Where FPR = False Positives / (False Positives + True Negatives)\n",
    "\n",
    "**Business Meaning:**\n",
    "- Innocent individuals from all demographic groups equally protected from false approvals\n",
    "- Prevents systematic over-penalization of specific groups\n",
    "- Focuses on fairness for those who should NOT receive positive outcomes\n",
    "\n",
    "**When to Use:**\n",
    "- Criminal justice systems (protect innocent people)\n",
    "- Fraud detection (avoid falsely flagging legitimate transactions)\n",
    "- Security screening (minimize false alarms for innocent people)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Key Differences\n",
    "\n",
    "| Metric | Focuses On | Protection Priority | Use Case |\n",
    "|--------|------------|-------------------|----------|\n",
    "| **Equal Opportunity** | Qualified individuals only | Missing talent | Talent acquisition |\n",
    "| **Average Odds** | Both qualified & innocent | Comprehensive fairness measurement | High-stakes decisions |\n",
    "| **Predictive Equality** | Innocent individuals only | False approvals | Risk/security systems |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Computational Analysis\n",
    "\n",
    "Let's implement and compare these three merit-based fairness metrics using the Adult Income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from jurity.fairness import BinaryFairnessMetrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the Adult Income dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "          'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "          'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "data = pd.read_csv(url, names=columns, skipinitialspace=True)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(data['income'].value_counts())\n",
    "print(\"\\nGender distribution:\")\n",
    "print(data['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# Remove rows with missing values (marked as '?')\n",
    "data = data.replace('?', np.nan).dropna()\n",
    "\n",
    "# Prepare features for modeling\n",
    "# Select relevant features\n",
    "features = ['age', 'workclass', 'education', 'marital_status', 'occupation', \n",
    "           'relationship', 'race', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "X = data[features].copy()\n",
    "y = (data['income'] == '>50K').astype(int)  # Binary target: 1 for >50K, 0 for <=50K\n",
    "sensitive_attribute = (data['sex'] == 'Female').astype(int)  # 1 for Female, 0 for Male\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "categorical_cols = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race']\n",
    "for col in categorical_cols:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Reset indices to ensure alignment\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "sensitive_attribute = sensitive_attribute.reset_index(drop=True)\n",
    "\n",
    "print(f\"Processed dataset shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "print(f\"Sensitive attribute distribution: {sensitive_attribute.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and train model\n",
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
    "    X, y, sensitive_attribute, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Test set accuracy: {(y_pred == y_test).mean():.3f}\")\n",
    "print(f\"Test set size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Merit-Based Fairness Metrics using Jurity\n",
    "bfm = BinaryFairnessMetrics()\n",
    "\n",
    "# Equal Opportunity\n",
    "equal_opportunity_score = bfm.EqualOpportunity.get_score(\n",
    "    labels=y_test.values,\n",
    "    predictions=y_pred,\n",
    "    memberships=sensitive_test.values\n",
    ")\n",
    "\n",
    "# Average Odds - metric measuring distance from Equalized Odds fairness constraint\n",
    "average_odds_score = bfm.AverageOdds.get_score(\n",
    "    labels=y_test.values,\n",
    "    predictions=y_pred,\n",
    "    memberships=sensitive_test.values\n",
    ")\n",
    "\n",
    "# Predictive Equality\n",
    "predictive_equality_score = bfm.PredictiveEquality.get_score(\n",
    "    labels=y_test.values,\n",
    "    predictions=y_pred,\n",
    "    memberships=sensitive_test.values\n",
    ")\n",
    "\n",
    "print(\"=== MERIT-BASED FAIRNESS METRICS RESULTS ===\")\n",
    "print(f\"Equal Opportunity Score: {equal_opportunity_score:.4f}\")\n",
    "print(f\"Average Odds Score: {average_odds_score:.4f}\")\n",
    "print(f\"Predictive Equality Score: {predictive_equality_score:.4f}\")\n",
    "print(\"\\nNote: Scores closer to 0 indicate better fairness (smaller differences between groups)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual calculation and verification of metrics\n",
    "def calculate_confusion_matrix_by_group(y_true, y_pred, sensitive):\n",
    "    \"\"\"Calculate confusion matrix metrics by sensitive group\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for group in [0, 1]:  # 0=Male, 1=Female\n",
    "        mask = sensitive == group\n",
    "        y_true_group = y_true[mask]\n",
    "        y_pred_group = y_pred[mask]\n",
    "        \n",
    "        # Confusion matrix\n",
    "        tn = ((y_true_group == 0) & (y_pred_group == 0)).sum()\n",
    "        tp = ((y_true_group == 1) & (y_pred_group == 1)).sum()\n",
    "        fn = ((y_true_group == 1) & (y_pred_group == 0)).sum()\n",
    "        fp = ((y_true_group == 0) & (y_pred_group == 1)).sum()\n",
    "        \n",
    "        # Calculate rates\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # True Positive Rate\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n",
    "        \n",
    "        group_name = 'Female' if group == 1 else 'Male'\n",
    "        results[group_name] = {\n",
    "            'TPR': tpr,\n",
    "            'FPR': fpr,\n",
    "            'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn,\n",
    "            'Total': len(y_true_group)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate metrics by group\n",
    "group_metrics = calculate_confusion_matrix_by_group(y_test.values, y_pred, sensitive_test.values)\n",
    "\n",
    "print(\"=== DETAILED GROUP PERFORMANCE METRICS ===\")\n",
    "for group, metrics in group_metrics.items():\n",
    "    print(f\"\\n{group} Group:\")\n",
    "    print(f\"  Total samples: {metrics['Total']}\")\n",
    "    print(f\"  True Positive Rate (TPR): {metrics['TPR']:.4f}\")\n",
    "    print(f\"  False Positive Rate (FPR): {metrics['FPR']:.4f}\")\n",
    "    print(f\"  Confusion Matrix: TP={metrics['TP']}, TN={metrics['TN']}, FP={metrics['FP']}, FN={metrics['FN']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual calculation of merit-based fairness metrics\n",
    "male_tpr = group_metrics['Male']['TPR']\n",
    "female_tpr = group_metrics['Female']['TPR']\n",
    "male_fpr = group_metrics['Male']['FPR']\n",
    "female_fpr = group_metrics['Female']['FPR']\n",
    "\n",
    "# Calculate fairness metric differences\n",
    "equal_opportunity_diff = abs(female_tpr - male_tpr)\n",
    "predictive_equality_diff = abs(female_fpr - male_fpr)\n",
    "average_odds_diff = (equal_opportunity_diff + predictive_equality_diff) / 2\n",
    "\n",
    "print(\"=== MANUAL VERIFICATION OF FAIRNESS METRICS ===\")\n",
    "print(f\"\\nEqual Opportunity (TPR difference):\")\n",
    "print(f\"  Male TPR: {male_tpr:.4f}\")\n",
    "print(f\"  Female TPR: {female_tpr:.4f}\")\n",
    "print(f\"  Difference: {equal_opportunity_diff:.4f}\")\n",
    "print(f\"  Jurity Score: {equal_opportunity_score:.4f}\")\n",
    "print(f\"  âœ“ Match: {abs(equal_opportunity_diff - equal_opportunity_score) < 0.001}\")\n",
    "\n",
    "print(f\"\\nPredictive Equality (FPR difference):\")\n",
    "print(f\"  Male FPR: {male_fpr:.4f}\")\n",
    "print(f\"  Female FPR: {female_fpr:.4f}\")\n",
    "print(f\"  Difference: {predictive_equality_diff:.4f}\")\n",
    "print(f\"  Jurity Score: {predictive_equality_score:.4f}\")\n",
    "print(f\"  âœ“ Match: {abs(predictive_equality_diff - predictive_equality_score) < 0.001}\")\n",
    "\n",
    "print(f\"\\nAverage Odds (Average of TPR and FPR differences):\")\n",
    "print(f\"  Calculated Average: {average_odds_diff:.4f}\")\n",
    "print(f\"  Jurity Score: {average_odds_score:.4f}\")\n",
    "print(f\"  âœ“ Match: {abs(average_odds_diff - average_odds_score) < 0.001}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization dashboard\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "fig.suptitle('Merit-Based Fairness Metrics Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Group Performance Comparison\n",
    "groups = ['Male', 'Female']\n",
    "tpr_values = [male_tpr, female_tpr]\n",
    "fpr_values = [male_fpr, female_fpr]\n",
    "\n",
    "x = np.arange(len(groups))\n",
    "width = 0.35\n",
    "\n",
    "axes[0,0].bar(x - width/2, tpr_values, width, label='TPR (True Positive Rate)', alpha=0.8)\n",
    "axes[0,0].bar(x + width/2, fpr_values, width, label='FPR (False Positive Rate)', alpha=0.8)\n",
    "axes[0,0].set_xlabel('Demographic Group')\n",
    "axes[0,0].set_ylabel('Rate')\n",
    "axes[0,0].set_title('Performance Rates by Group')\n",
    "axes[0,0].set_xticks(x)\n",
    "axes[0,0].set_xticklabels(groups)\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Equal Opportunity Visualization\n",
    "axes[0,1].bar(groups, tpr_values, color=['skyblue', 'lightcoral'], alpha=0.8)\n",
    "axes[0,1].set_ylabel('True Positive Rate')\n",
    "axes[0,1].set_title(f'Equal Opportunity\\n(TPR Difference: {equal_opportunity_diff:.4f})')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(tpr_values):\n",
    "    axes[0,1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Predictive Equality Visualization\n",
    "axes[0,2].bar(groups, fpr_values, color=['lightgreen', 'orange'], alpha=0.8)\n",
    "axes[0,2].set_ylabel('False Positive Rate')\n",
    "axes[0,2].set_title(f'Predictive Equality\\n(FPR Difference: {predictive_equality_diff:.4f})')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "for i, v in enumerate(fpr_values):\n",
    "    axes[0,2].text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 4. Fairness Scores Comparison\n",
    "fairness_scores = [equal_opportunity_score, predictive_equality_score, average_odds_score]\n",
    "fairness_names = ['Equal\\nOpportunity', 'Predictive\\nEquality', 'Average\\nOdds']\n",
    "colors = ['skyblue', 'lightgreen', 'plum']\n",
    "\n",
    "bars = axes[1,0].bar(fairness_names, fairness_scores, color=colors, alpha=0.8)\n",
    "axes[1,0].set_ylabel('Fairness Score')\n",
    "axes[1,0].set_title('Merit-Based Fairness Scores\\n(Lower = More Fair)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "for bar, score in zip(bars, fairness_scores):\n",
    "    axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "                  f'{score:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# 5. Confusion Matrix Heatmaps\n",
    "for idx, (group, metrics) in enumerate(group_metrics.items()):\n",
    "    cm = np.array([[metrics['TN'], metrics['FP']], \n",
    "                   [metrics['FN'], metrics['TP']]])\n",
    "    \n",
    "    im = axes[1, idx+1].imshow(cm, cmap='Blues', alpha=0.8)\n",
    "    axes[1, idx+1].set_title(f'{group} Group\\nConfusion Matrix')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            text = axes[1, idx+1].text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "    \n",
    "    axes[1, idx+1].set_xticks([0, 1])\n",
    "    axes[1, idx+1].set_yticks([0, 1])\n",
    "    axes[1, idx+1].set_xticklabels(['Predicted: â‰¤50K', 'Predicted: >50K'])\n",
    "    axes[1, idx+1].set_yticklabels(['Actual: â‰¤50K', 'Actual: >50K'])\n",
    "\n",
    "# 6. Business Risk Assessment\n",
    "def assess_merit_fairness_risk(eo_score, pe_score, ao_score):\n",
    "    \"\"\"Assess business risk based on merit-based fairness scores\"\"\"\n",
    "    risks = []\n",
    "    \n",
    "    if eo_score > 0.1:\n",
    "        risks.append(f\"HIGH RISK: Equal Opportunity gap ({eo_score:.3f}) - Losing qualified talent\")\n",
    "    elif eo_score > 0.05:\n",
    "        risks.append(f\"MEDIUM RISK: Equal Opportunity gap ({eo_score:.3f}) - Monitor talent pipeline\")\n",
    "    else:\n",
    "        risks.append(f\"LOW RISK: Equal Opportunity gap ({eo_score:.3f}) - Good talent fairness\")\n",
    "    \n",
    "    if pe_score > 0.1:\n",
    "        risks.append(f\"HIGH RISK: Predictive Equality gap ({pe_score:.3f}) - Unfair false approvals\")\n",
    "    elif pe_score > 0.05:\n",
    "        risks.append(f\"MEDIUM RISK: Predictive Equality gap ({pe_score:.3f}) - Monitor false positives\")\n",
    "    else:\n",
    "        risks.append(f\"LOW RISK: Predictive Equality gap ({pe_score:.3f}) - Good false positive fairness\")\n",
    "    \n",
    "    if ao_score > 0.1:\n",
    "        risks.append(f\"HIGH RISK: Average Odds gap ({ao_score:.3f}) - Far from Equalized Odds goal\")\n",
    "    elif ao_score > 0.05:\n",
    "        risks.append(f\"MEDIUM RISK: Average Odds gap ({ao_score:.3f}) - Progress needed toward Equalized Odds\")\n",
    "    else:\n",
    "        risks.append(f\"LOW RISK: Average Odds gap ({ao_score:.3f}) - Close to Equalized Odds goal\")\n",
    "    \n",
    "    return risks\n",
    "\n",
    "risk_assessment = assess_merit_fairness_risk(equal_opportunity_score, predictive_equality_score, average_odds_score)\n",
    "\n",
    "# 7. Risk Assessment Text\n",
    "axes[2,0].axis('off')\n",
    "risk_text = \"BUSINESS RISK ASSESSMENT:\\n\\n\" + \"\\n\\n\".join(risk_assessment)\n",
    "axes[2,0].text(0.05, 0.95, risk_text, transform=axes[2,0].transAxes, \n",
    "              fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "              bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
    "\n",
    "# 8. Metric Interpretation Guide\n",
    "axes[2,1].axis('off')\n",
    "interpretation_text = (\n",
    "    \"METRIC INTERPRETATION:\\n\\n\"\n",
    "    \"Equal Opportunity:\\n\"\n",
    "    \"â€¢ Focuses on qualified individuals\\n\"\n",
    "    \"â€¢ Measures TPR gap between groups\\n\"\n",
    "    \"â€¢ Critical for talent acquisition\\n\\n\"\n",
    "    \"Predictive Equality:\\n\"\n",
    "    \"â€¢ Focuses on innocent individuals\\n\"\n",
    "    \"â€¢ Measures FPR gap between groups\\n\"\n",
    "    \"â€¢ Critical for false accusation protection\\n\\n\"\n",
    "    \"Average Odds:\\n\"\n",
    "    \"â€¢ Metric measuring distance from\\n\"\n",
    "    \"  Equalized Odds (fairness goal)\\n\"\n",
    "    \"â€¢ Combines TPR and FPR gaps\\n\"\n",
    "    \"â€¢ Best for tracking comprehensive fairness\"\n",
    ")\n",
    "axes[2,1].text(0.05, 0.95, interpretation_text, transform=axes[2,1].transAxes,\n",
    "              fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "              bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightyellow\", alpha=0.8))\n",
    "\n",
    "# 9. Recommendations\n",
    "axes[2,2].axis('off')\n",
    "recommendations = (\n",
    "    \"ACTIONABLE RECOMMENDATIONS:\\n\\n\"\n",
    "    f\"1. TALENT PIPELINE:\\n\"\n",
    "    f\"   TPR Gap: {equal_opportunity_diff:.3f}\\n\"\n",
    "    f\"   {'âœ“ Acceptable' if equal_opportunity_diff < 0.05 else 'âš  Review recruitment'}\\n\\n\"\n",
    "    f\"2. FALSE POSITIVE PROTECTION:\\n\"\n",
    "    f\"   FPR Gap: {predictive_equality_diff:.3f}\\n\"\n",
    "    f\"   {'âœ“ Fair protection' if predictive_equality_diff < 0.05 else 'âš  Review thresholds'}\\n\\n\"\n",
    "    f\"3. EQUALIZED ODDS PROGRESS:\\n\"\n",
    "    f\"   Average Odds: {average_odds_diff:.3f}\\n\"\n",
    "    f\"   {'âœ“ Close to goal' if average_odds_diff < 0.05 else 'âš  Needs improvement'}\\n\\n\"\n",
    "    \"Next Steps:\\n\"\n",
    "    \"â€¢ Monitor metrics regularly\\n\"\n",
    "    \"â€¢ Audit decision thresholds\\n\"\n",
    "    \"â€¢ Review training data balance\"\n",
    ")\n",
    "axes[2,2].text(0.05, 0.95, recommendations, transform=axes[2,2].transAxes,\n",
    "              fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "              bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Business Impact Analysis\n",
    "\n",
    "### Key Findings from Our Analysis\n",
    "\n",
    "Based on the computational results above, we can assess the merit-based fairness of our income prediction model:\n",
    "\n",
    "#### Equal Opportunity Analysis\n",
    "- **Metric Focus:** Ensures qualified candidates from both genders have equal chances of being predicted as high earners\n",
    "- **Business Impact:** Critical for talent retention and equal opportunity in hiring/promotion decisions\n",
    "- **Risk Level:** Determined by TPR difference between demographic groups\n",
    "\n",
    "#### Predictive Equality Analysis\n",
    "- **Metric Focus:** Ensures individuals who shouldn't be predicted as high earners have equal protection from false positives\n",
    "- **Business Impact:** Prevents unfair advantages or false elevation of unqualified candidates\n",
    "- **Risk Level:** Determined by FPR difference between demographic groups\n",
    "\n",
    "#### Average Odds Analysis\n",
    "- **Metric Focus:** Quantifies how far the model is from achieving Equalized Odds (the fairness constraint where both TPR and FPR are equal across groups)\n",
    "- **Business Impact:** Provides a single comprehensive metric to track progress toward balanced fairness for both qualified and unqualified individuals\n",
    "- **Risk Level:** Combined assessment of both TPR and FPR fairness gaps\n",
    "- **Note:** Average Odds is a *measurement tool*, while Equalized Odds is the *fairness goal* we aim to achieve\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Each Metric\n",
    "\n",
    "**Use Equal Opportunity when:**\n",
    "- Primary concern is not missing qualified talent\n",
    "- Hiring for competitive positions where qualifications matter most\n",
    "- Cost of false negatives (missing good candidates) is high\n",
    "\n",
    "**Use Predictive Equality when:**\n",
    "- Primary concern is avoiding false approvals or unfair treatment\n",
    "- Security or risk assessment applications\n",
    "- Cost of false positives (wrongly selecting unqualified) is high\n",
    "\n",
    "**Use Average Odds when:**\n",
    "- Need to measure comprehensive fairness across both concerns\n",
    "- Want a single metric to track progress toward Equalized Odds\n",
    "- High-stakes decisions with broad impact requiring balanced fairness\n",
    "- Regulatory requirements for demonstrating fairness improvements\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¼ Stakeholder Implications\n",
    "\n",
    "### For HR and Talent Teams\n",
    "Merit-based fairness metrics directly impact talent management:\n",
    "- **Equal Opportunity** ensures no qualified talent is systematically overlooked\n",
    "- **Predictive Equality** prevents unfair advantages for unqualified candidates\n",
    "- **Average Odds** provides a comprehensive score to track overall fairness progress toward Equalized Odds\n",
    "\n",
    "### For Risk Management\n",
    "These metrics help assess and mitigate business risks:\n",
    "- Talent pipeline risks (losing qualified candidates)\n",
    "- Quality risks (selecting unqualified candidates)\n",
    "- Legal risks (discrimination in merit-based decisions)\n",
    "- Reputational risks (perceived unfairness in high-stakes decisions)\n",
    "\n",
    "### For Executive Leadership\n",
    "Merit-based fairness metrics support strategic objectives:\n",
    "- Ensure competitive advantage through fair talent acquisition\n",
    "- Maintain organizational reputation for fairness\n",
    "- Meet regulatory requirements while optimizing for merit\n",
    "- Balance fairness with business performance objectives\n",
    "- Track progress toward fairness goals using Average Odds as a comprehensive KPI\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
