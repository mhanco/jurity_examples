{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Legal Compliance Metrics: Regulatory Fairness in AI Systems\n\n## Executive Summary\n\n**Legal Compliance Metrics** are fairness measures specifically designed to help organizations meet regulatory requirements and avoid discrimination lawsuits. These metrics focus on **selection-rate parity** across demographic groups, which is often how regulators initially screen for potential discrimination, though full legal analysis also considers job-relatedness and business necessity.\n\n### Key Business Insights:\n- **Regulatory Protection**: Designed to meet specific legal standards (80% Rule, EEOC guidelines)\n- **Selection-Rate Focus**: Measures whether different groups receive positive outcomes at similar rates\n- **Legal Defensibility**: Provides measurable evidence of non-discriminatory practices\n- **Risk Mitigation**: Reduces exposure to discrimination lawsuits and regulatory penalties\n\n### Deployment Recommendation:\n**ESSENTIAL** - Legal Compliance metrics are mandatory for any AI system used in regulated contexts such as hiring, lending, insurance, or housing decisions."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Understanding Legal Compliance Metrics\n\nLegal compliance metrics emerged from decades of civil rights legislation and court decisions. They represent an initial screening tool for algorithmic fairness in regulated industries.\n\n### The Two Core Legal Compliance Metrics:\n\n#### 1. Disparate Impact\n- **Legal Foundation**: Based on the \"80% Rule\" from EEOC Uniform Guidelines (1978)\n- **Measurement**: Ratio of selection rates between groups\n- **Threshold**: Protected group rate ‚â• 80% of majority group rate\n- **Focus**: Employment law compliance\n\n#### 2. Statistical Parity\n- **Legal Foundation**: Equal treatment doctrine from civil rights law\n- **Measurement**: Difference in positive prediction rates\n- **Threshold**: Typically ¬±5% difference considered acceptable\n- **Focus**: Broader anti-discrimination compliance\n\n### Key Differences from Merit-Based Metrics:\n| Aspect | Legal Compliance | Merit-Based |\n|--------|------------------|-------------|\n| **Focus** | Selection-rate parity | Fair outcomes for qualified |\n| **Qualification Consideration** | Not directly measured | Central |\n| **Legal Basis** | Specific statutes | General fairness principles |\n| **Business Impact** | Risk reduction | Performance optimization |\n| **Measurement** | Group-level rates | Individual-level fairness |\n\n### Important Legal Nuance:\nThese metrics measure selection-rate parity, which regulators use as an **initial screen** for potential discrimination. However, under frameworks like Title VII and EEOC guidelines, differences in selection rates may be legally justified if the employer can demonstrate **job-relatedness and business necessity**. Think of these metrics as red flags that trigger deeper legal analysis, not absolute prohibitions.\n\n### When Legal Compliance Metrics Are Required:\n- **Employment decisions** (hiring, promotion, termination)\n- **Credit and lending** (mortgages, loans, credit cards)\n- **Insurance** (pricing, coverage decisions)\n- **Housing** (rental, sales, zoning)\n- **Education** (admissions, financial aid)\n- **Healthcare** (treatment access, insurance coverage)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from jurity.fairness import BinaryFairnessMetrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Ready to analyze Legal Compliance Metrics:\")\n",
    "print(\"‚Ä¢ Disparate Impact (80% Rule)\")\n",
    "print(\"‚Ä¢ Statistical Parity (Equal Treatment)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "We'll use the Adult Income dataset to demonstrate legal compliance metrics in a realistic employment context - the exact scenario where these metrics are legally required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Adult Income dataset\n",
    "print(\"=== LOADING ADULT INCOME DATASET ===\")\n",
    "print(\"Context: Employment income prediction (where legal compliance is mandatory)\")\n",
    "print()\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', \n",
    "                'marital_status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "df = pd.read_csv(url, names=column_names, skipinitialspace=True)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nIncome distribution (target variable):\")\n",
    "print(df['income'].value_counts())\n",
    "\n",
    "print(f\"\\nGender distribution (protected attribute):\")\n",
    "print(df['sex'].value_counts())\n",
    "\n",
    "# Show cross-tabulation for legal compliance context\n",
    "print(f\"\\nIncome by Gender (Legal Compliance Focus):\")\n",
    "income_by_gender = pd.crosstab(df['sex'], df['income'], margins=True)\n",
    "print(income_by_gender)\n",
    "\n",
    "# Calculate actual selection rates (important for legal compliance)\n",
    "print(f\"\\nActual Selection Rates by Gender:\")\n",
    "female_rate = (df[df['sex'] == 'Female']['income'] == '>50K').mean()\n",
    "male_rate = (df[df['sex'] == 'Male']['income'] == '>50K').mean()\n",
    "print(f\"Female selection rate: {female_rate:.3f} ({female_rate*100:.1f}%)\")\n",
    "print(f\"Male selection rate: {male_rate:.3f} ({male_rate*100:.1f}%)\")\n",
    "\n",
    "# Calculate disparate impact in actual data\n",
    "actual_disparate_impact = female_rate / male_rate\n",
    "print(f\"\\nüìä Actual Disparate Impact: {actual_disparate_impact:.3f}\")\n",
    "print(f\"80% Rule Compliance: {'‚úÖ PASS' if actual_disparate_impact >= 0.8 else '‚ùå FAIL'}\")\n",
    "print(f\"(Threshold: Female rate must be ‚â•80% of male rate)\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess data\n",
    "print(\"=== DATA PREPROCESSING FOR LEGAL COMPLIANCE ANALYSIS ===\")\n",
    "\n",
    "# Handle missing values\n",
    "df_clean = df.replace('?', np.nan).dropna()\n",
    "print(f\"After removing missing values: {df_clean.shape[0]} rows\")\n",
    "\n",
    "# Create binary variables for legal compliance analysis\n",
    "df_clean['high_income'] = (df_clean['income'] == '>50K').astype(int)\n",
    "df_clean['is_male'] = (df_clean['sex'] == 'Male').astype(int)\n",
    "\n",
    "print(f\"\\nLegal Compliance Variables:\")\n",
    "print(f\"‚Ä¢ Target: high_income (1 = >$50K, 0 = ‚â§$50K)\")\n",
    "print(f\"‚Ä¢ Protected attribute: is_male (1 = Male, 0 = Female)\")\n",
    "\n",
    "# Select features for modeling (excluding protected attributes per legal best practice)\n",
    "features = ['age', 'education_num', 'hours_per_week', 'capital_gain', 'capital_loss']\n",
    "X = df_clean[features]\n",
    "y = df_clean['high_income']\n",
    "sensitive_attr = df_clean['is_male']\n",
    "\n",
    "print(f\"\\nModel features: {features}\")\n",
    "print(f\"Note: Gender is excluded from model features (legal best practice)\")\n",
    "print(f\"Final dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "# Show baseline statistics for legal compliance\n",
    "baseline_stats = df_clean.groupby('sex')['high_income'].agg(['count', 'sum', 'mean']).round(3)\n",
    "baseline_stats.columns = ['Total_Count', 'High_Income_Count', 'Selection_Rate']\n",
    "print(f\"\\nBaseline Selection Rates:\")\n",
    "print(baseline_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "We'll train a model and then evaluate it using both legal compliance metrics to understand how they differ in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for legal compliance evaluation\n",
    "print(\"=== MODEL TRAINING ===\")\n",
    "print(\"Training employment prediction model (subject to legal compliance requirements)\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
    "    X, y, sensitive_attr, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Model performance\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Overall accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Calculate prediction rates by gender (key for legal compliance)\n",
    "female_mask = sensitive_test == 0\n",
    "male_mask = sensitive_test == 1\n",
    "\n",
    "female_pred_rate = y_pred[female_mask].mean()\n",
    "male_pred_rate = y_pred[male_mask].mean()\n",
    "\n",
    "print(f\"\\nPredicted Selection Rates:\")\n",
    "print(f\"Female: {female_pred_rate:.3f} ({female_pred_rate*100:.1f}%)\")\n",
    "print(f\"Male: {male_pred_rate:.3f} ({male_pred_rate*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìã Ready for Legal Compliance Analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legal Compliance Metrics Analysis\n",
    "\n",
    "Now let's evaluate our model using both legal compliance metrics and understand what each tells us about regulatory risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Legal Compliance Metrics using Jurity\n",
    "print(\"=== LEGAL COMPLIANCE METRICS ANALYSIS ===\")\n",
    "\n",
    "bfm = BinaryFairnessMetrics()\n",
    "\n",
    "# 1. Disparate Impact (80% Rule)\n",
    "disparate_impact_score = bfm.DisparateImpact.get_score(\n",
    "    predictions=y_pred,\n",
    "    memberships=sensitive_test.values\n",
    ")\n",
    "\n",
    "# 2. Statistical Parity (Equal Treatment)\n",
    "statistical_parity_score = bfm.StatisticalParity.get_score(\n",
    "    predictions=y_pred,\n",
    "    memberships=sensitive_test.values\n",
    ")\n",
    "\n",
    "print(\"\\nüèõÔ∏è DISPARATE IMPACT ANALYSIS (80% Rule)\")\n",
    "print(f\"Disparate Impact Score: {disparate_impact_score:.3f}\")\n",
    "print(f\"Interpretation:\")\n",
    "print(f\"‚Ä¢ Score represents Male/Female selection rate ratio\")\n",
    "print(f\"‚Ä¢ Legal requirement: Female rate ‚â• 80% of Male rate\")\n",
    "print(f\"‚Ä¢ Inverse ratio (Female/Male): {1/disparate_impact_score:.3f}\")\n",
    "\n",
    "# Legal compliance assessment for Disparate Impact\n",
    "female_male_ratio = 1 / disparate_impact_score\n",
    "if female_male_ratio >= 0.8:\n",
    "    di_status = \"‚úÖ LEGALLY COMPLIANT\"\n",
    "    di_risk = \"LOW\"\n",
    "elif female_male_ratio >= 0.7:\n",
    "    di_status = \"‚ö†Ô∏è BORDERLINE - LEGAL REVIEW NEEDED\"\n",
    "    di_risk = \"MODERATE\"\n",
    "else:\n",
    "    di_status = \"‚ùå NON-COMPLIANT - LEGAL RISK\"\n",
    "    di_risk = \"HIGH\"\n",
    "\n",
    "print(f\"\\nLegal Assessment: {di_status}\")\n",
    "print(f\"Legal Risk Level: {di_risk}\")\n",
    "print(f\"Female/Male Ratio: {female_male_ratio:.3f} (minimum required: 0.800)\")\n",
    "\n",
    "print(\"\\nüìä STATISTICAL PARITY ANALYSIS (Equal Treatment)\")\n",
    "print(f\"Statistical Parity Score: {statistical_parity_score:.3f}\")\n",
    "print(f\"Interpretation:\")\n",
    "print(f\"‚Ä¢ Score represents Male - Female selection rate difference\")\n",
    "print(f\"‚Ä¢ Positive = Male advantage, Negative = Female advantage\")\n",
    "print(f\"‚Ä¢ Typical tolerance: ¬±0.05 (5 percentage points)\")\n",
    "\n",
    "# Legal compliance assessment for Statistical Parity\n",
    "if abs(statistical_parity_score) <= 0.05:\n",
    "    sp_status = \"‚úÖ ACCEPTABLE DIFFERENCE\"\n",
    "    sp_risk = \"LOW\"\n",
    "elif abs(statistical_parity_score) <= 0.1:\n",
    "    sp_status = \"‚ö†Ô∏è NOTABLE DIFFERENCE - MONITOR\"\n",
    "    sp_risk = \"MODERATE\"\n",
    "else:\n",
    "    sp_status = \"‚ùå SIGNIFICANT DISPARITY\"\n",
    "    sp_risk = \"HIGH\"\n",
    "\n",
    "print(f\"\\nAssessment: {sp_status}\")\n",
    "print(f\"Risk Level: {sp_risk}\")\n",
    "print(f\"Difference: {statistical_parity_score:+.3f} (tolerance: ¬±0.050)\")\n",
    "\n",
    "print(f\"\\nüéØ COMPARATIVE ANALYSIS\")\n",
    "print(f\"Disparate Impact focuses on: Ratio compliance (80% rule)\")\n",
    "print(f\"Statistical Parity focuses on: Absolute difference\")\n",
    "print(f\"\")\n",
    "if di_risk == \"LOW\" and sp_risk == \"LOW\":\n",
    "    overall_risk = \"‚úÖ LOW LEGAL RISK\"\n",
    "elif di_risk == \"HIGH\" or sp_risk == \"HIGH\":\n",
    "    overall_risk = \"‚ùå HIGH LEGAL RISK\"\n",
    "else:\n",
    "    overall_risk = \"‚ö†Ô∏è MODERATE LEGAL RISK\"\n",
    "    \n",
    "print(f\"Overall Legal Risk Assessment: {overall_risk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Comparison: Disparate Impact vs Statistical Parity\n",
    "\n",
    "Let's dive deeper into how these two metrics differ in their mathematical approach and legal implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed comparison of legal compliance metrics\n",
    "print(\"=== DETAILED METRIC COMPARISON ===\")\n",
    "\n",
    "# Manual calculations to show the mathematics\n",
    "female_count = np.sum(sensitive_test == 0)\n",
    "male_count = np.sum(sensitive_test == 1)\n",
    "female_selected = np.sum(y_pred[sensitive_test == 0])\n",
    "male_selected = np.sum(y_pred[sensitive_test == 1])\n",
    "\n",
    "female_rate_manual = female_selected / female_count\n",
    "male_rate_manual = male_selected / male_count\n",
    "\n",
    "print(\"üìä RAW NUMBERS:\")\n",
    "print(f\"Female group: {female_selected:,} selected out of {female_count:,} total ({female_rate_manual:.1%})\")\n",
    "print(f\"Male group: {male_selected:,} selected out of {male_count:,} total ({male_rate_manual:.1%})\")\n",
    "\n",
    "print(\"\\nüßÆ MATHEMATICAL CALCULATIONS:\")\n",
    "\n",
    "# Disparate Impact calculation\n",
    "manual_di_ratio = male_rate_manual / female_rate_manual\n",
    "manual_female_male_ratio = female_rate_manual / male_rate_manual\n",
    "\n",
    "print(f\"\\n1. DISPARATE IMPACT (Ratio Method):\")\n",
    "print(f\"   Formula: Minority_Rate / Majority_Rate\")\n",
    "print(f\"   Calculation: {female_rate_manual:.3f} / {male_rate_manual:.3f} = {manual_female_male_ratio:.3f}\")\n",
    "print(f\"   Jurity result: {1/disparate_impact_score:.3f}\")\n",
    "print(f\"   Legal threshold: ‚â•0.800\")\n",
    "print(f\"   Compliance: {'PASS' if manual_female_male_ratio >= 0.8 else 'FAIL'}\")\n",
    "\n",
    "# Statistical Parity calculation  \n",
    "manual_sp_diff = male_rate_manual - female_rate_manual\n",
    "\n",
    "print(f\"\\n2. STATISTICAL PARITY (Difference Method):\")\n",
    "print(f\"   Formula: Majority_Rate - Minority_Rate\")\n",
    "print(f\"   Calculation: {male_rate_manual:.3f} - {female_rate_manual:.3f} = {manual_sp_diff:+.3f}\")\n",
    "print(f\"   Jurity result: {statistical_parity_score:+.3f}\")\n",
    "print(f\"   Typical tolerance: ¬±0.050\")\n",
    "print(f\"   Assessment: {'ACCEPTABLE' if abs(manual_sp_diff) <= 0.05 else 'CONCERNING'}\")\n",
    "\n",
    "print(f\"\\nüîç WHY THESE METRICS CAN GIVE DIFFERENT RESULTS:\")\n",
    "\n",
    "# Demonstrate scenarios where they disagree\n",
    "print(f\"\\nCurrent scenario:\")\n",
    "print(f\"‚Ä¢ Disparate Impact cares about: {manual_female_male_ratio:.3f} ‚â• 0.800\")\n",
    "print(f\"‚Ä¢ Statistical Parity cares about: |{manual_sp_diff:.3f}| ‚â§ 0.050\")\n",
    "\n",
    "# Show example scenarios\n",
    "print(f\"\\nüìã EXAMPLE SCENARIOS WHERE THEY DISAGREE:\")\n",
    "scenarios = [\n",
    "    {\"female_rate\": 0.12, \"male_rate\": 0.15, \"context\": \"Low base rates\"},\n",
    "    {\"female_rate\": 0.40, \"male_rate\": 0.50, \"context\": \"High base rates\"},\n",
    "    {\"female_rate\": 0.08, \"male_rate\": 0.10, \"context\": \"Very low base rates\"}\n",
    "]\n",
    "\n",
    "for scenario in scenarios:\n",
    "    f_rate = scenario[\"female_rate\"]\n",
    "    m_rate = scenario[\"male_rate\"]\n",
    "    di_ratio = f_rate / m_rate\n",
    "    sp_diff = m_rate - f_rate\n",
    "    \n",
    "    print(f\"\\n{scenario['context']} (F:{f_rate:.2f}, M:{m_rate:.2f}):\")\n",
    "    print(f\"  Disparate Impact: {di_ratio:.3f} ({'PASS' if di_ratio >= 0.8 else 'FAIL'})\")\n",
    "    print(f\"  Statistical Parity: {sp_diff:+.3f} ({'OK' if abs(sp_diff) <= 0.05 else 'FAIL'})\")\n",
    "    \n",
    "    if (di_ratio >= 0.8) != (abs(sp_diff) <= 0.05):\n",
    "        print(f\"  ‚ö†Ô∏è METRICS DISAGREE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Legal Compliance Visualization\n",
    "\n",
    "Let's create visualizations that clearly show how our model performs on both legal compliance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive legal compliance visualization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 16))\n",
    "fig.suptitle('Legal Compliance Metrics: Comprehensive Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Selection Rates by Gender\n",
    "selection_data = pd.DataFrame({\n",
    "    'Gender': ['Female', 'Male'],\n",
    "    'Selection_Rate': [female_rate_manual, male_rate_manual],\n",
    "    'Count_Selected': [female_selected, male_selected],\n",
    "    'Total_Count': [female_count, male_count]\n",
    "})\n",
    "\n",
    "bars = axes[0, 0].bar(selection_data['Gender'], selection_data['Selection_Rate'], \n",
    "                      color=['pink', 'lightblue'], alpha=0.7)\n",
    "axes[0, 0].set_title('Selection Rates by Gender')\n",
    "axes[0, 0].set_ylabel('Selection Rate')\n",
    "axes[0, 0].set_ylim(0, max(selection_data['Selection_Rate']) * 1.2)\n",
    "\n",
    "# Add value labels and counts\n",
    "for i, (rate, selected, total) in enumerate(zip(selection_data['Selection_Rate'], \n",
    "                                                 selection_data['Count_Selected'],\n",
    "                                                 selection_data['Total_Count'])):\n",
    "    axes[0, 0].text(i, rate + 0.01, f'{rate:.3f}\\n({selected}/{total})', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Disparate Impact Visualization\n",
    "di_threshold = 0.8\n",
    "current_di = manual_female_male_ratio\n",
    "\n",
    "# Create disparate impact gauge\n",
    "di_values = [current_di, di_threshold, 1.0]\n",
    "di_labels = [f'Current\\n{current_di:.3f}', f'Threshold\\n{di_threshold:.3f}', 'Perfect\\n1.000']\n",
    "di_colors = ['red' if current_di < di_threshold else 'green', 'orange', 'blue']\n",
    "\n",
    "bars = axes[0, 1].bar(di_labels, di_values, color=di_colors, alpha=0.7)\n",
    "axes[0, 1].set_title('Disparate Impact (80% Rule)')\n",
    "axes[0, 1].set_ylabel('Female/Male Rate Ratio')\n",
    "axes[0, 1].axhline(y=di_threshold, color='red', linestyle='--', alpha=0.7, label='Legal Minimum')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "for bar, value in zip(bars, di_values):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Statistical Parity Visualization\n",
    "sp_tolerance = 0.05\n",
    "current_sp = abs(manual_sp_diff)\n",
    "\n",
    "sp_values = [current_sp, sp_tolerance]\n",
    "sp_labels = [f'Current Diff\\n{manual_sp_diff:+.3f}', f'Tolerance\\n¬±{sp_tolerance:.3f}']\n",
    "sp_colors = ['red' if current_sp > sp_tolerance else 'green', 'orange']\n",
    "\n",
    "bars = axes[0, 2].bar(sp_labels, [current_sp, sp_tolerance], color=sp_colors, alpha=0.7)\n",
    "axes[0, 2].set_title('Statistical Parity (Equal Treatment)')\n",
    "axes[0, 2].set_ylabel('Absolute Rate Difference')\n",
    "axes[0, 2].axhline(y=sp_tolerance, color='red', linestyle='--', alpha=0.7, label='Typical Tolerance')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# 4. Legal Risk Assessment Matrix\n",
    "risk_matrix = pd.DataFrame({\n",
    "    'Metric': ['Disparate Impact', 'Statistical Parity'],\n",
    "    'Current_Value': [current_di, abs(manual_sp_diff)],\n",
    "    'Threshold': [di_threshold, sp_tolerance],\n",
    "    'Status': ['PASS' if current_di >= di_threshold else 'FAIL',\n",
    "              'PASS' if current_sp <= sp_tolerance else 'FAIL']\n",
    "})\n",
    "\n",
    "# Create status visualization\n",
    "status_colors = ['green' if status == 'PASS' else 'red' for status in risk_matrix['Status']]\n",
    "bars = axes[1, 0].bar(risk_matrix['Metric'], [1, 1], color=status_colors, alpha=0.7)\n",
    "axes[1, 0].set_title('Legal Compliance Status')\n",
    "axes[1, 0].set_ylabel('Compliance Status')\n",
    "axes[1, 0].set_ylim(0, 1.2)\n",
    "\n",
    "for i, (metric, status) in enumerate(zip(risk_matrix['Metric'], risk_matrix['Status'])):\n",
    "    axes[1, 0].text(i, 0.5, status, ha='center', va='center', \n",
    "                    fontweight='bold', fontsize=14, color='white')\n",
    "\n",
    "# 5. Historical Context (Actual vs Predicted)\n",
    "comparison_data = pd.DataFrame({\n",
    "    'Scenario': ['Actual Data', 'Model Predictions'],\n",
    "    'Female_Rate': [female_rate, female_rate_manual],\n",
    "    'Male_Rate': [male_rate, male_rate_manual],\n",
    "    'Disparate_Impact': [female_rate/male_rate, manual_female_male_ratio]\n",
    "})\n",
    "\n",
    "x = np.arange(len(comparison_data['Scenario']))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 1].bar(x - width/2, comparison_data['Female_Rate'], width, \n",
    "               label='Female Rate', color='pink', alpha=0.7)\n",
    "axes[1, 1].bar(x + width/2, comparison_data['Male_Rate'], width, \n",
    "               label='Male Rate', color='lightblue', alpha=0.7)\n",
    "axes[1, 1].set_title('Actual Data vs Model Predictions')\n",
    "axes[1, 1].set_ylabel('Selection Rate')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(comparison_data['Scenario'])\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 6. Metric Sensitivity Analysis\n",
    "# Show how small changes in rates affect compliance\n",
    "rate_changes = np.arange(-0.02, 0.025, 0.005)\n",
    "di_impacts = []\n",
    "sp_impacts = []\n",
    "\n",
    "for change in rate_changes:\n",
    "    new_female_rate = female_rate_manual + change\n",
    "    new_di = new_female_rate / male_rate_manual\n",
    "    new_sp = abs(male_rate_manual - new_female_rate)\n",
    "    di_impacts.append(new_di)\n",
    "    sp_impacts.append(new_sp)\n",
    "\n",
    "axes[1, 2].plot(rate_changes, di_impacts, 'b-', label='Disparate Impact', linewidth=2)\n",
    "axes[1, 2].axhline(y=0.8, color='blue', linestyle='--', alpha=0.7)\n",
    "axes[1, 2].set_title('Sensitivity to Female Rate Changes')\n",
    "axes[1, 2].set_xlabel('Change in Female Rate')\n",
    "axes[1, 2].set_ylabel('Disparate Impact Ratio')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Legal Framework Comparison\n",
    "framework_data = pd.DataFrame({\n",
    "    'Framework': ['80% Rule\\n(EEOC)', 'Equal Treatment\\n(Civil Rights)'],\n",
    "    'Current_Score': [current_di, abs(manual_sp_diff)],\n",
    "    'Compliance': ['PASS' if current_di >= 0.8 else 'FAIL',\n",
    "                   'PASS' if abs(manual_sp_diff) <= 0.05 else 'FAIL']\n",
    "})\n",
    "\n",
    "colors = ['green' if comp == 'PASS' else 'red' for comp in framework_data['Compliance']]\n",
    "bars = axes[2, 0].bar(framework_data['Framework'], framework_data['Current_Score'], \n",
    "                      color=colors, alpha=0.7)\n",
    "axes[2, 0].set_title('Legal Framework Compliance')\n",
    "axes[2, 0].set_ylabel('Metric Value')\n",
    "\n",
    "for i, (score, comp) in enumerate(zip(framework_data['Current_Score'], framework_data['Compliance'])):\n",
    "    axes[2, 0].text(i, score + 0.01, f'{score:.3f}\\n{comp}', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 8. Business Risk Assessment\n",
    "risk_factors = ['Regulatory Fines', 'Lawsuits', 'Reputation', 'Compliance Costs']\n",
    "risk_levels = [1 if di_risk == 'LOW' and sp_risk == 'LOW' else \n",
    "               2 if di_risk == 'MODERATE' or sp_risk == 'MODERATE' else 3\n",
    "               for _ in risk_factors]\n",
    "\n",
    "risk_colors = ['green' if r == 1 else 'orange' if r == 2 else 'red' for r in risk_levels]\n",
    "bars = axes[2, 1].bar(risk_factors, risk_levels, color=risk_colors, alpha=0.7)\n",
    "axes[2, 1].set_title('Business Risk Assessment')\n",
    "axes[2, 1].set_ylabel('Risk Level (1=Low, 3=High)')\n",
    "axes[2, 1].tick_params(axis='x', rotation=45)\n",
    "axes[2, 1].set_ylim(0, 3.5)\n",
    "\n",
    "# 9. Overall Compliance Dashboard\n",
    "overall_status = \"COMPLIANT\" if current_di >= 0.8 and abs(manual_sp_diff) <= 0.05 else \"NON-COMPLIANT\"\n",
    "overall_color = 'green' if overall_status == \"COMPLIANT\" else 'red'\n",
    "\n",
    "axes[2, 2].text(0.5, 0.7, 'Legal Compliance', ha='center', va='center', \n",
    "                fontsize=18, fontweight='bold', transform=axes[2, 2].transAxes)\n",
    "axes[2, 2].text(0.5, 0.5, overall_status, ha='center', va='center', \n",
    "                fontsize=24, fontweight='bold', color=overall_color,\n",
    "                transform=axes[2, 2].transAxes)\n",
    "axes[2, 2].text(0.5, 0.3, f'DI: {current_di:.3f}\\nSP: {abs(manual_sp_diff):.3f}', \n",
    "                ha='center', va='center', fontsize=12,\n",
    "                transform=axes[2, 2].transAxes)\n",
    "axes[2, 2].text(0.5, 0.1, 'Both metrics must pass', ha='center', va='center', \n",
    "                fontsize=10, style='italic', transform=axes[2, 2].transAxes)\n",
    "axes[2, 2].set_xlim(0, 1)\n",
    "axes[2, 2].set_ylim(0, 1)\n",
    "axes[2, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legal Risk Assessment and Business Impact\n",
    "\n",
    "Let's analyze the business implications of our legal compliance findings and provide concrete recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive legal risk assessment\n",
    "print(\"=\"*80)\n",
    "print(\"LEGAL COMPLIANCE RISK ASSESSMENT & BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"REGULATORY CONTEXT: Employment Income Prediction\")\n",
    "print(f\"APPLICABLE LAWS: Title VII, EEOC Guidelines, Equal Pay Act\")\n",
    "print(f\"PROTECTED CHARACTERISTIC: Gender (Male vs Female)\")\n",
    "print(f\"SAMPLE SIZE: {len(y_test):,} employment decisions\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"LEGAL COMPLIANCE RESULTS\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "print(f\"\\nüèõÔ∏è DISPARATE IMPACT (80% RULE - EEOC STANDARD):\")\n",
    "print(f\"   Current Ratio: {manual_female_male_ratio:.3f}\")\n",
    "print(f\"   Legal Minimum: 0.800\")\n",
    "print(f\"   Status: {di_status}\")\n",
    "print(f\"   \")\n",
    "print(f\"   Raw Numbers:\")\n",
    "print(f\"   ‚Ä¢ Female selection rate: {female_rate_manual:.1%} ({female_selected:,} of {female_count:,})\")\n",
    "print(f\"   ‚Ä¢ Male selection rate: {male_rate_manual:.1%} ({male_selected:,} of {male_count:,})\")\n",
    "print(f\"   ‚Ä¢ Gap analysis: Female rate is {female_male_ratio*100:.1f}% of male rate\")\n",
    "\n",
    "print(f\"\\nüìä STATISTICAL PARITY (EQUAL TREATMENT STANDARD):\")\n",
    "print(f\"   Current Difference: {manual_sp_diff:+.3f}\")\n",
    "print(f\"   Typical Tolerance: ¬±0.050\")\n",
    "print(f\"   Status: {sp_status}\")\n",
    "print(f\"   \")\n",
    "print(f\"   Interpretation:\")\n",
    "print(f\"   ‚Ä¢ Males have {abs(manual_sp_diff)*100:.1f}pp higher selection rate\")\n",
    "print(f\"   ‚Ä¢ Difference of {abs(manual_sp_diff)*100:.1f}pp {'exceeds' if abs(manual_sp_diff) > 0.05 else 'is within'} typical tolerance\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"BUSINESS RISK ANALYSIS\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "# Calculate business impact metrics\n",
    "total_decisions = len(y_test)\n",
    "affected_females = int(female_count * abs(manual_sp_diff)) if manual_sp_diff > 0 else 0\n",
    "potential_liability = affected_females * 50000  # Rough estimate of per-person liability\n",
    "\n",
    "print(f\"\\nüí∞ FINANCIAL RISK ASSESSMENT:\")\n",
    "if di_risk == \"HIGH\" or sp_risk == \"HIGH\":\n",
    "    financial_risk = \"SIGNIFICANT\"\n",
    "    cost_range = \"$500K - $5M+\"\n",
    "    action_urgency = \"IMMEDIATE\"\n",
    "elif di_risk == \"MODERATE\" or sp_risk == \"MODERATE\":\n",
    "    financial_risk = \"MODERATE\"\n",
    "    cost_range = \"$100K - $500K\"\n",
    "    action_urgency = \"WITHIN 30 DAYS\"\n",
    "else:\n",
    "    financial_risk = \"LOW\"\n",
    "    cost_range = \"<$100K\"\n",
    "    action_urgency = \"ROUTINE MONITORING\"\n",
    "\n",
    "print(f\"   ‚Ä¢ Overall Financial Risk: {financial_risk}\")\n",
    "print(f\"   ‚Ä¢ Estimated Cost Range: {cost_range}\")\n",
    "print(f\"   ‚Ä¢ Potentially Affected Individuals: ~{affected_females:,}\")\n",
    "print(f\"   ‚Ä¢ Action Timeline: {action_urgency}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è LEGAL RISK FACTORS:\")\n",
    "risk_factors = {\n",
    "    \"Class Action Lawsuit\": \"HIGH\" if di_risk == \"HIGH\" else \"MODERATE\" if di_risk == \"MODERATE\" else \"LOW\",\n",
    "    \"EEOC Investigation\": \"HIGH\" if female_male_ratio < 0.7 else \"MODERATE\" if female_male_ratio < 0.8 else \"LOW\",\n",
    "    \"Regulatory Fines\": \"MODERATE\" if di_risk != \"LOW\" or sp_risk != \"LOW\" else \"LOW\",\n",
    "    \"Reputation Damage\": \"HIGH\" if overall_status == \"NON-COMPLIANT\" else \"LOW\",\n",
    "    \"Regulatory Scrutiny\": \"MODERATE\" if di_risk != \"LOW\" else \"LOW\"\n",
    "}\n",
    "\n",
    "for factor, risk in risk_factors.items():\n",
    "    emoji = \"üö®\" if risk == \"HIGH\" else \"‚ö†Ô∏è\" if risk == \"MODERATE\" else \"‚úÖ\"\n",
    "    print(f\"   ‚Ä¢ {factor}: {emoji} {risk}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"STRATEGIC RECOMMENDATIONS\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìã IMMEDIATE ACTIONS (Required):\")\n",
    "if overall_status == \"NON-COMPLIANT\":\n",
    "    print(f\"   1. üö® HALT DEPLOYMENT - Model fails legal compliance\")\n",
    "    print(f\"   2. üö® Legal review required before any production use\")\n",
    "    print(f\"   3. üö® Implement bias mitigation techniques:\")\n",
    "    print(f\"      ‚Ä¢ Threshold adjustment for demographic parity\")\n",
    "    print(f\"      ‚Ä¢ Post-processing calibration\")\n",
    "    print(f\"      ‚Ä¢ Training data rebalancing\")\n",
    "    print(f\"   4. üö® Document compliance efforts for legal protection\")\n",
    "else:\n",
    "    print(f\"   1. ‚úÖ Model passes basic legal compliance\")\n",
    "    print(f\"   2. ‚úÖ Implement enhanced monitoring system\")\n",
    "    print(f\"   3. ‚úÖ Establish monthly compliance reporting\")\n",
    "    print(f\"   4. ‚úÖ Train HR team on bias monitoring\")\n",
    "\n",
    "print(f\"\\nüîÑ ONGOING MONITORING STRATEGY:\")\n",
    "print(f\"   ‚Ä¢ Disparate Impact: Monitor monthly, alert if ratio < 0.85\")\n",
    "print(f\"   ‚Ä¢ Statistical Parity: Monitor weekly, alert if difference > 0.03\")\n",
    "print(f\"   ‚Ä¢ Audit trail: Log all predictions with demographic breakdowns\")\n",
    "print(f\"   ‚Ä¢ Legal review: Quarterly assessment with employment attorney\")\n",
    "\n",
    "print(f\"\\nüíº BUSINESS PROCESS INTEGRATION:\")\n",
    "print(f\"   ‚Ä¢ HR Training: Legal compliance requirements for AI systems\")\n",
    "print(f\"   ‚Ä¢ Executive Reporting: Monthly legal risk dashboard\")\n",
    "print(f\"   ‚Ä¢ Vendor Management: Ensure third-party AI tools meet standards\")\n",
    "print(f\"   ‚Ä¢ Documentation: Maintain compliance records for regulatory audits\")\n",
    "\n",
    "print(f\"\\nüéì LEGAL COMPLIANCE BEST PRACTICES:\")\n",
    "print(f\"   1. Always test BOTH disparate impact and statistical parity\")\n",
    "print(f\"   2. Document business justification for any AI hiring tools\")\n",
    "print(f\"   3. Provide alternative selection procedures if adverse impact exists\")\n",
    "print(f\"   4. Regular validation studies to show job relevance\")\n",
    "print(f\"   5. Employee training on unconscious bias and fair hiring\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"CONCLUSION: {'‚úÖ PROCEED WITH MONITORING' if overall_status == 'COMPLIANT' else '‚ùå COMPLIANCE WORK REQUIRED'}\")\n",
    "print(f\"\")\n",
    "if overall_status == \"COMPLIANT\":\n",
    "    print(f\"This model demonstrates acceptable legal compliance for employment\")\n",
    "    print(f\"decisions. Implement robust monitoring to maintain compliance and\")\n",
    "    print(f\"protect against regulatory risk.\")\n",
    "else:\n",
    "    print(f\"This model requires immediate attention to address legal compliance\")\n",
    "    print(f\"issues. Do not deploy until disparate impact and statistical parity\")\n",
    "    print(f\"metrics meet acceptable thresholds.\")\n",
    "print(f\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Insights: Legal Compliance vs Merit-Based Fairness\n\n### Understanding the Fundamental Difference:\n\n**Legal Compliance Metrics (Disparate Impact & Statistical Parity):**\n- Focus on **selection-rate parity** across demographic groups\n- Serve as initial screening tools for potential discrimination\n- Required by law in many jurisdictions\n- Important legal nuance: Differences in selection rates may be legally justified through job-relatedness and business necessity\n- Designed to prevent discrimination in historically biased systems\n\n**Merit-Based Metrics (Equal Opportunity, Average Odds):**\n- Focus on **fair outcomes** for qualified individuals\n- Explicitly allow different overall rates if justified by qualification differences\n- Optimize for both accuracy and fairness\n- Better align with business performance goals\n\n### The Legal Framework Reality:\n\nLegal compliance metrics provide a **statistical trigger** for further analysis. Under U.S. employment law (Title VII, EEOC guidelines), failing the 80% rule doesn't automatically mean illegal discrimination‚Äîbut it does shift the burden to the employer to demonstrate that the selection criteria are:\n1. **Job-related** - Connected to actual job requirements\n2. **Business necessity** - Essential for safe and efficient operations\n3. **Validated** - Shown to predict job performance\n\nSimilarly, passing these metrics doesn't guarantee legal safety if the selection process is otherwise discriminatory.\n\n### When Each Type Matters:\n\n#### Use Legal Compliance Metrics When:\n- ‚úÖ **Regulatory requirement** (hiring, lending, housing)\n- ‚úÖ **High legal risk** environment\n- ‚úÖ **Historical discrimination** in the domain\n- ‚úÖ **Public sector** or government contracting\n- ‚úÖ **Initial fairness screening** before deployment\n\n#### Use Merit-Based Metrics When:\n- ‚úÖ **Performance optimization** is critical\n- ‚úÖ **Clear qualification standards** exist and can be defended\n- ‚úÖ **Internal business decisions** (less regulated)\n- ‚úÖ **Innovation and competitiveness** are priorities\n- ‚úÖ **Job-relatedness** can be demonstrated\n\n### Best Practice:\n**Monitor BOTH types simultaneously** - Legal compliance metrics for regulatory screening and risk management, merit-based metrics for business optimization and performance fairness. This dual approach provides comprehensive fairness coverage while managing legal risk.\n\n### Business Impact:\n- **Legal Protection**: Reduces lawsuit and regulatory risk by catching statistical red flags\n- **Stakeholder Trust**: Demonstrates commitment to non-discrimination\n- **Operational Clarity**: Provides clear initial pass/fail criteria\n- **Industry Standards**: Aligns with established legal frameworks\n- **Defensibility**: Enables evidence-based justification when needed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Legal Resources and Documentation\n",
    "\n",
    "### Legal Framework References:\n",
    "- **EEOC Uniform Guidelines on Employee Selection (1978)**: Establishes the 80% rule for disparate impact\n",
    "- **Griggs v. Duke Power Co. (1971)**: Supreme Court case establishing disparate impact doctrine\n",
    "- **Title VII of Civil Rights Act (1964)**: Prohibits employment discrimination\n",
    "- **Equal Credit Opportunity Act (1974)**: Prohibits credit discrimination\n",
    "\n",
    "### Technical Implementation:\n",
    "- **Jurity Library Documentation**: [Disparate Impact](https://jurity.readthedocs.io/en/latest/fairness_metrics.html#disparate-impact) and [Statistical Parity](https://jurity.readthedocs.io/en/latest/fairness_metrics.html#statistical-parity)\n",
    "- **NIST AI Risk Management Framework**: Guidelines for responsible AI deployment\n",
    "- **IEEE Standards for AI Systems**: Technical standards for algorithmic accountability\n",
    "\n",
    "### Industry Guidelines:\n",
    "- **Partnership on AI**: Best practices for fair and beneficial AI\n",
    "- **Aequitas Toolkit**: Open-source bias audit toolkit\n",
    "- **Google AI Principles**: Responsible AI development guidelines\n",
    "\n",
    "### Compliance Monitoring:\n",
    "- Document all bias testing and mitigation efforts\n",
    "- Maintain audit trails for regulatory review\n",
    "- Regular validation studies to demonstrate business necessity\n",
    "- Legal review of AI systems before deployment\n",
    "\n",
    "**Disclaimer**: This analysis is for educational purposes only. Consult with employment attorneys and compliance experts for specific legal guidance in your jurisdiction and industry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}